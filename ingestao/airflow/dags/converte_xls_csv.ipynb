{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importa Modulos necessários\n",
    "Nesse exemplo vamos importar o modulo do Pandas que vai ser necessário para abrir o dataframe no formato CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd, os, glob, re, csv, shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seta Variaveis e cria Lista\n",
    "Cria as variáveis com as pastas origem e destino da conversão de XLS para CSV e cria uma lista para conversão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variaveis\n",
    "PastaXLS = 'dados/DadosSalicNetXLS/'\n",
    "PastaCSV = 'dados/DadosSalicNetCSV/'\n",
    "lista_arquivos = os.listdir(PastaXLS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo o conteúdo e convertendo\n",
    "Vamos um for com a lista dos arquivos da pasta de arquivos XLS, com base nessa lista, vamos fazer a leitura de cada arquivo de `i` arquivo com variável `wd` que serve pro arquivo xls ser lido pelo modulo importado `xlrd` (por causa do encoding e tal não conseguiu ler direto com o `read_excel`), posteriormente lemos o `wd` com o `read_excel`. Como teremos que mudar a extenção do arquivo de `.xls` para `.csv`, criei uma váriavel `nome` para remover a extensão de `i`, posteriormente usando o `to_excel`, uso essa variavel `nome`, concatenando com `.csv` onde gero o arquivo final no formato que queremos.\n",
    "\n",
    "Foi realizada também uma alteração dos Headers sem espaço e sem acentos, facilitando o acesso as informações, são criados arquivos temporários com o final `nh.csv` a partir dos gerados inicialmente e posteriormente eles sobrescrevem os criados inicialmente. Isso ajudou na concatenação deles para geração de um único dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in lista_arquivos:\n",
    "    ano = (re.findall(\"dados_pj_(\\d+).xls\", i))[0]\n",
    "    wb = xlrd.open_workbook(PastaXLS + '/' + i, encoding_override='ISO-8859-1')\n",
    "    arquivoExcel = pd.read_excel(wb).assign(ano_corrente=ano)\n",
    "    nome = i.rpartition('.')[0]\n",
    "    arquivo = PastaCSV + '/' + nome + '.csv'\n",
    "    arquivoExcel.to_csv (arquivo, index = None, header=True)\n",
    "\n",
    "    ## Mudando o nome do header dos arquivos\n",
    "    headerCagado = arquivo\n",
    "    headerBacana = os.path.splitext(headerCagado)[0] + \"_nh.csv\"\n",
    "\n",
    "    with open(headerCagado, newline='') as entrada, open(headerBacana, 'w', newline='') as saida:\n",
    "        r = csv.reader(entrada)\n",
    "        w = csv.writer(saida)\n",
    "\n",
    "        next(r, None)\n",
    "        w.writerow(['cpf_cnpj','incentivador','nro_projeto','nome_projeto','uf_projeto','valor_incentivo','ano'])\n",
    "\n",
    "        for row in r:\n",
    "            w.writerow(row)\n",
    "\n",
    "    ## Sobrescrevendo o CSV zuado com o corrigido:\n",
    "    shutil.move(headerBacana, arquivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando o Dataframe consolidado:\n",
    "Vamos consolidar todos os arquivos `CSV` em um único dataframe, a idéia é podermos tratar os dados antes da geração do `CSV` final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lista de todos os CSVs no diretório\n",
    "lista_csvs = glob.glob(os.path.join(PastaCSV, \"*.csv\"))\n",
    "\n",
    "## Criando um dataframe zerado com os Datatypes definidos\n",
    "dados = pd.DataFrame()\n",
    "\n",
    "## Inserindo todos os CSVs no dataframe criado:\n",
    "dados = pd.concat([pd.read_csv(l) for l in lista_csvs], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando os dados:\n",
    "Em alguns campos não existe um padrão então vamos tratar:\n",
    "* Deixar os Campos String todos com letra maiuscula\n",
    "* Alterar o formato do valor para 2 casas depois da virgula\n",
    "* Alterar o ano, pois está com um digito depois da virgula a idéia é nenhum.\n",
    "* Ordenação dos dados por Ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## Tratando os datatypes:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#dados = dados.fillna(0)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dados \u001b[39m=\u001b[39m dados\u001b[39m.\u001b[39;49mastype({\u001b[39m'\u001b[39;49m\u001b[39mcpf_cnpj\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mincentivador\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mnro_projeto\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mnome_projeto\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39muf_projeto\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mano\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[1;32m      5\u001b[0m \u001b[39m## Deixando as string maiusculas para padronizar a busca\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dados[\u001b[39m'\u001b[39m\u001b[39mincentivador\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dados[\u001b[39m'\u001b[39m\u001b[39mincentivador\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mupper()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:6226\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6224\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m copy \u001b[39melse\u001b[39;00m col\n\u001b[1;32m   6225\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 6226\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mcdt, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6227\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[1;32m   6229\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   6230\u001b[0m     \u001b[39m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[1;32m   6231\u001b[0m     \u001b[39m# GH 24704: use iloc to handle duplicate column names\u001b[39;00m\n\u001b[1;32m   6232\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:140\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot astype a timedelta from [\u001b[39m\u001b[39m{\u001b[39;00marr\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m] to [\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m     \u001b[39m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[39m# GH#45151\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (values \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "## Tratando os datatypes:\n",
    "#dados = dados.fillna(0)\n",
    "dados = dados.astype({'cpf_cnpj': 'int','incentivador':'str','nro_projeto':'str','nome_projeto':'str','uf_projeto':'str','ano': 'int'})\n",
    "\n",
    "## Deixando as string maiusculas para padronizar a busca\n",
    "dados['incentivador'] = dados['incentivador'].str.upper()\n",
    "dados['nome_projeto'] = dados['nome_projeto'].str.upper()\n",
    "display(dados)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando os registros cagados:\n",
    "De todos os dados, foram encontrados 12 registros cagados onde o ano é igual a 0, o que indica uma quebra em algumas linnhas de alguns CSVs, mas foi coisa pouca, vou idenficar esses dados, extrair para um Excel, tratar manualmente esse 12 registros e trazer devolta para o dataframe final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ano\n",
       "0         12\n",
       "1993       2\n",
       "1994      20\n",
       "1995      84\n",
       "1996    1018\n",
       "1997    1774\n",
       "1998    1881\n",
       "1999    2042\n",
       "2000    2398\n",
       "2001    2346\n",
       "2002    2652\n",
       "2003    2891\n",
       "2004    4047\n",
       "2005    4778\n",
       "2006    5826\n",
       "2007    6524\n",
       "2008    6360\n",
       "2009    5983\n",
       "2010    7436\n",
       "2011    8081\n",
       "2012    7856\n",
       "2013    8075\n",
       "2014    8045\n",
       "2015    7411\n",
       "2016    7091\n",
       "2017    7580\n",
       "2018    8402\n",
       "2019    9185\n",
       "2020    8516\n",
       "2021    9293\n",
       "2022    9315\n",
       "2023      14\n",
       "Name: ano, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpf_cnpj</th>\n",
       "      <th>incentivador</th>\n",
       "      <th>nro_projeto</th>\n",
       "      <th>nome_projeto</th>\n",
       "      <th>uf_projeto</th>\n",
       "      <th>valor_incentivo</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156937</th>\n",
       "      <td>0</td>\n",
       "      <td>183598</td>\n",
       "      <td>CIRCO DOS SONHOS - TURNÊ 1</td>\n",
       "      <td>SP</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156935</th>\n",
       "      <td>0</td>\n",
       "      <td>184336</td>\n",
       "      <td>Atos e Palhaços ArteClownizAção</td>\n",
       "      <td>SP</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156934</th>\n",
       "      <td>2043201000100</td>\n",
       "      <td>COZIMAX MÓVEIS MIRASSOL LTDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156933</th>\n",
       "      <td>0</td>\n",
       "      <td>211747</td>\n",
       "      <td>É NÓIS NA FITA - CURSO GRATUITO DE CINEMA 2022</td>\n",
       "      <td>SP</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156932</th>\n",
       "      <td>2043201000100</td>\n",
       "      <td>COZIMAX MÓVEIS MIRASSOL LTDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156931</th>\n",
       "      <td>0</td>\n",
       "      <td>190965</td>\n",
       "      <td>O CASO MARTIN PICHE</td>\n",
       "      <td>RJ</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156930</th>\n",
       "      <td>2043201000100</td>\n",
       "      <td>COZIMAX MÓVEIS MIRASSOL LTDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156929</th>\n",
       "      <td>0</td>\n",
       "      <td>191847</td>\n",
       "      <td>É NÓIS NA FITA - CURSO GRATUITO DE CINEMA 2020</td>\n",
       "      <td>SP</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156928</th>\n",
       "      <td>2043201000100</td>\n",
       "      <td>COZIMAX MÓVEIS MIRASSOL LTDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156927</th>\n",
       "      <td>0</td>\n",
       "      <td>221192</td>\n",
       "      <td>Superações (Ano 2)</td>\n",
       "      <td>SP</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156926</th>\n",
       "      <td>2043201000100</td>\n",
       "      <td>COZIMAX MÓVEIS MIRASSOL LTDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156936</th>\n",
       "      <td>17543049000193</td>\n",
       "      <td>UOL CURSOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cpf_cnpj                  incentivador  \\\n",
       "156937               0                        183598   \n",
       "156935               0                        184336   \n",
       "156934   2043201000100  COZIMAX MÓVEIS MIRASSOL LTDA   \n",
       "156933               0                        211747   \n",
       "156932   2043201000100  COZIMAX MÓVEIS MIRASSOL LTDA   \n",
       "156931               0                        190965   \n",
       "156930   2043201000100  COZIMAX MÓVEIS MIRASSOL LTDA   \n",
       "156929               0                        191847   \n",
       "156928   2043201000100  COZIMAX MÓVEIS MIRASSOL LTDA   \n",
       "156927               0                        221192   \n",
       "156926   2043201000100  COZIMAX MÓVEIS MIRASSOL LTDA   \n",
       "156936  17543049000193                    UOL CURSOS   \n",
       "\n",
       "                                           nro_projeto nome_projeto  \\\n",
       "156937                      CIRCO DOS SONHOS - TURNÊ 1           SP   \n",
       "156935                 Atos e Palhaços ArteClownizAção           SP   \n",
       "156934                                               0            0   \n",
       "156933  É NÓIS NA FITA - CURSO GRATUITO DE CINEMA 2022           SP   \n",
       "156932                                               0            0   \n",
       "156931                             O CASO MARTIN PICHE           RJ   \n",
       "156930                                               0            0   \n",
       "156929  É NÓIS NA FITA - CURSO GRATUITO DE CINEMA 2020           SP   \n",
       "156928                                               0            0   \n",
       "156927                              Superações (Ano 2)           SP   \n",
       "156926                                               0            0   \n",
       "156936                                               0            0   \n",
       "\n",
       "       uf_projeto  valor_incentivo  ano  \n",
       "156937    40000.0           2019.0    0  \n",
       "156935     8000.0           2019.0    0  \n",
       "156934        0.0              0.0    0  \n",
       "156933    36000.0           2021.0    0  \n",
       "156932        0.0              0.0    0  \n",
       "156931    36000.0           2021.0    0  \n",
       "156930        0.0              0.0    0  \n",
       "156929    18000.0           2020.0    0  \n",
       "156928        0.0              0.0    0  \n",
       "156927    48000.0           2022.0    0  \n",
       "156926        0.0              0.0    0  \n",
       "156936        0.0              0.0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Validando o numero de linhas por ano:\n",
    "volume_linha_ano = dados.groupby(['ano'])['ano'].count()\n",
    "display(volume_linha_ano)\n",
    "\n",
    "## Gerando as linhas cagadas com o ano igual a zero:\n",
    "dados_cagados = dados.loc[dados['ano'] == 0]\n",
    "display(dados_cagados)\n",
    "\n",
    "## Gerando um csv de nome linhas_cagadas.csv\n",
    "arquivo_cagado='arquivo_cagado.csv'\n",
    "dados_cagados.to_csv (arquivo_cagado, index = None, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando o dataframe com o CSV corrigido\n",
    "Após corrigido, vamos montar um dataframe de nome `corrigido` e remover as linhas do consolidado que estão com o ano `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arquivo_corrigido.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## Formatando os dados corrigidos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m corrigido \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m----> 3\u001b[0m corrigido \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39marquivo_corrigido.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m corrigido[\u001b[39m'\u001b[39m\u001b[39mincentivador\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m corrigido[\u001b[39m'\u001b[39m\u001b[39mincentivador\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mupper()\n\u001b[1;32m      5\u001b[0m corrigido[\u001b[39m'\u001b[39m\u001b[39mnome_projeto\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m corrigido[\u001b[39m'\u001b[39m\u001b[39mnome_projeto\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mupper()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arquivo_corrigido.csv'"
     ]
    }
   ],
   "source": [
    "## Formatando os dados corrigidos\n",
    "corrigido = pd.DataFrame()\n",
    "corrigido = pd.read_csv('dados/arquivo_corrigido.csv')\n",
    "corrigido['incentivador'] = corrigido['incentivador'].str.upper()\n",
    "corrigido['nome_projeto'] = corrigido['nome_projeto'].str.upper()\n",
    "\n",
    "## Removendo as linhas com ano 0 \n",
    "dados = dados.loc[dados['ano'] != 0]\n",
    "\n",
    "## Fazendo a junção e ordenando os dados por ano\n",
    "dados = pd.concat([dados, corrigido], ignore_index=True)\n",
    "dados = dados.sort_values('ano')\n",
    "\n",
    "## Validação final pra ver se não ficou nada errado:\n",
    "dados_cagados = dados.loc[dados['ano'] == 0]\n",
    "display(dados_cagados)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando o CSV final:\n",
    "Com todos os campos tratados vamos gerar um CSV final consolidado com todos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_final='dados_consolidados.csv'\n",
    "dados.to_csv (arquivo_final, index = None, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultando registros por ano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consultando Registros:\n",
    "#a = int(input('Qual ano você deseja consultar?'))\n",
    "#consulta = dados.loc[dados['ano'] == a]\n",
    "#display(consulta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultando Registros por CNPJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consultando Registros:\n",
    "#a = int(input('Qual CNPJ você deseja consultar?'))\n",
    "#consulta = dados.loc[dados['cpf_cnpj'] == a]\n",
    "#display(consulta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando um arquivo Parquet do dataframe final\n",
    "Vou criar um parquet ao invés de um CSV devido a velocidade de consulta e as possibilidades que ele vai trazer, a ídeia é posteriormente usar o formato Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gravando o Dataframe em Parquet\n",
    "#caminho_parquet='DadosSalicNetParquet/'\n",
    "#dados = dados.astype({'nro_projeto': 'int'})\n",
    "#dados.to_parquet(caminho_parquet + 'dados.parquet.gzip',compression='gzip') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total de incentivos por estado ao longo do tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados.groupby('uf_projeto').valor_incentivo.sum().astype(int).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
